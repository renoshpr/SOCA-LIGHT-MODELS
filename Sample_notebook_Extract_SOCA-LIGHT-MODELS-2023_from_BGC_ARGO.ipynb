{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad04e51-f7b5-45b4-8b5c-ad54ad50fb9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h1> Sample notebook to extract SOCA-LIGHT-2023 profile from BGC-Argo Temp-Sal profiles and Satellite Ocean Color Matchups </h1></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b38459-e0b9-4b03-9ac8-f5d6b4cbaf1a",
   "metadata": {},
   "source": [
    "******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b616414-df06-40e3-bf4d-933cdbb7c0b0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><i> Renosh - November 2023 </i></div>\n",
    "<div style=\"text-align: right\"><i> Email: renosh.pr@imev-mer.fr </i></div>\n",
    "<div style=\"text-align: right\"><i> Email: pr.renosh@gmail.com </i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b3df02-a80e-4a32-b27f-dc3c70b4b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769765-05d0-420b-94e3-53da746b04c0",
   "metadata": {},
   "source": [
    "## 1) Load all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d43edb-ae1c-4425-a75d-4121befbadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#######################################################################################\n",
    "# Load all the libraries\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import import_ipynb\n",
    "from datetime import date, datetime, timedelta\n",
    "import datetime as dt\n",
    "# import oceans.sw_extras as swe\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "import timezonefinder, pytz\n",
    "tf = timezonefinder.TimezoneFinder()\n",
    "#######################################################################################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6ffc7-8f23-4420-b4e3-4cb3250336c6",
   "metadata": {},
   "source": [
    "*************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7609c40-f147-4688-a855-82b4b42ca453",
   "metadata": {},
   "source": [
    "## 2) Import SOCA-Light model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e679f4-8adc-48e4-8e49-a090f56cce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from FUNCTIONS.OTHER_FUNCTIONS import rad_date, rad_LC_hour, derive_ZPD,find_MLD\n",
    "from FUNCTIONS.PAR_ADJUSTED_FUNCTION import PAR_ADJUSTED_profiles\n",
    "from FUNCTIONS.ED380_ADJUSTED_FUNCTION import ED380_ADJUSTED_profiles\n",
    "from FUNCTIONS.ED412_ADJUSTED_FUNCTION import ED412_ADJUSTED_profiles\n",
    "from FUNCTIONS.ED490_ADJUSTED_FUNCTION import ED490_ADJUSTED_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59ba37-b6bb-4714-97f0-30e033f1e4c6",
   "metadata": {},
   "source": [
    "**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2d053-30d3-4787-be5d-5e99b1441e4c",
   "metadata": {},
   "source": [
    "## 3) Extraction of SOCA-light profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4b0e1-710a-4127-9952-3d0642309c3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract light profiles from input file and BGC-Argo file\n",
    "********************************************************************\n",
    "<div style=\"text-align: left\"><i> The path of the BGC-Argo file need to be precised in input file </i></div>\n",
    "<div style=\"text-align: left\"><i> The output files will be saved in the corresponding output folder for each variable. </i></div>\n",
    "<div style=\"text-align: left\"><i> For example SOCA-PAR outputs stored in OUTPUTS/PAR folder </i></div>\n",
    "<div style=\"text-align: left\"><i> If the path are correctly mention in '/INPUTS/inputs.xlsx' user will get outputs in corresponding folders. No need to change anything in this NOTEBOOK </i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17704b8-0af3-4e42-9516-efcbc7fec565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## The inputs from excel file a sample file (INPUTS/inputs.xlsx) \n",
    "## The output file name as DAC_WMO_CYCLE_ED490.txt format this can change as per users choice\n",
    "\n",
    "#######################################################################################\n",
    "# define output path (WHERE YOU WANT TO SAVE THE OUTPUT FILES)\n",
    "# PAR_OUT_PATH = pathlib.Path('/Users/renoshpr/Documents/BLUE_CLOUD/SOCA_CHL_2020/NOTEBOOK/PAR_ADJUSTED_MODEL_2022/PAR_ADJUSTED_Extraction_2023_51_depths/Output')\n",
    "curr_work_dir = Path.cwd()\n",
    "PAR_OUT_PATH = (''.join([str(curr_work_dir),'/OUTPUTS/PAR']))\n",
    "ED380_OUT_PATH = (''.join([str(curr_work_dir),'/OUTPUTS/ED380']))\n",
    "ED412_OUT_PATH = (''.join([str(curr_work_dir),'/OUTPUTS/ED412']))\n",
    "ED490_OUT_PATH = (''.join([str(curr_work_dir),'/OUTPUTS/ED490']))\n",
    "\n",
    "#######################################################################################\n",
    "# READ INPUTS FROM EXCEL FILE\n",
    "#\n",
    "input_file_name = (''.join([str(curr_work_dir),'/INPUTS/inputs.xlsx']))\n",
    "# input_file_name = 'inputs.xlsx'\n",
    "Inputs=pd.read_excel(str(input_file_name))\n",
    "\n",
    "for i in np.arange(len(Inputs)):\n",
    "    BGC_ARGO_NC_FILE = Inputs.BGC_ARGO_NC_FILE[i]\n",
    "    RHO412 = Inputs.RHO412[i]\n",
    "    RHO443 = Inputs.RHO443[i]\n",
    "    RHO490 = Inputs.RHO490[i]\n",
    "    RHO555 = Inputs.RHO555[i]\n",
    "    RHO670 = Inputs.RHO670[i]\n",
    "    PAR = Inputs.PAR[i]\n",
    "    KD490 = Inputs.KD490[i]\n",
    "    PAR_output_file = (''.join([str(PAR_OUT_PATH),'/',str(Inputs.DAC[i]),'_',str(Inputs.WMO[i]),'_',str(Inputs.N_CYCLE[i]),'_PAR.txt']))\n",
    "    ED380_output_file = (''.join([str(ED380_OUT_PATH),'/',str(Inputs.DAC[i]),'_',str(Inputs.WMO[i]),'_',str(Inputs.N_CYCLE[i]),'_ED380.txt']))\n",
    "    ED412_output_file = (''.join([str(ED412_OUT_PATH),'/',str(Inputs.DAC[i]),'_',str(Inputs.WMO[i]),'_',str(Inputs.N_CYCLE[i]),'_ED412.txt']))\n",
    "    ED490_output_file = (''.join([str(ED490_OUT_PATH),'/',str(Inputs.DAC[i]),'_',str(Inputs.WMO[i]),'_',str(Inputs.N_CYCLE[i]),'_ED490.txt']))\n",
    "    \n",
    "    #######################################################################################\n",
    "    \n",
    "    if os.path.isfile(BGC_ARGO_NC_FILE): # check Argo file exist\n",
    "        # LOAD THE BGC_ARGO file\n",
    "        #######################################################################################\n",
    "        # ADD the path of the Argo NC file\n",
    "        NC= NetCDFFile(str(BGC_ARGO_NC_FILE))\n",
    "    \n",
    "        # Check Parameter and its Data mode\n",
    "        PARAMETER=NC.variables['PARAMETER']\n",
    "        PARAMETER = ''.join(str(s, encoding='UTF-8') for s in PARAMETER)\n",
    "        PARAMETER = PARAMETER.split()\n",
    "\n",
    "        DATA_M = NC.variables['PARAMETER_DATA_MODE']\n",
    "        DATA_M  = ''.join(str(s, encoding='UTF-8') for s in DATA_M)\n",
    "        \n",
    "        # PRES_MODE = DATA_M[PARAMETER.index('PRES')]\n",
    "        TEMP_MODE = DATA_M[PARAMETER.index('TEMP')]\n",
    "        PSAL_MODE = DATA_M[PARAMETER.index('PSAL')]\n",
    "        \n",
    "        if ((TEMP_MODE=='D') and (PSAL_MODE=='D')): # check temp sal datamode\n",
    "            #######################################################################################\n",
    "            ##### EXTRACTING TEMP SAL PRES same depths FROM NC ARGO FILE ##########################\n",
    "            #######################################################################################\n",
    "            pres_1 = NC.variables['PRES_ADJUSTED'][:]\n",
    "            temp_1 = NC.variables['TEMP_ADJUSTED'][:]\n",
    "            sal_1 = NC.variables['PSAL_ADJUSTED'][:]             \n",
    "            pres_qc_1 = NC.variables['PRES_ADJUSTED_QC'][:]\n",
    "            temp_qc_1 = NC.variables['TEMP_ADJUSTED_QC'][:]\n",
    "            sal_qc_1 = NC.variables['PSAL_ADJUSTED_QC'][:]\n",
    "            LAT = float(NC.variables['LATITUDE'][:])\n",
    "            LON = float(NC.variables['LONGITUDE'][:])\n",
    "\n",
    "            pres1 = pres_1.filled(fill_value=np.nan)\n",
    "            pres_qc = pres_qc_1.filled(fill_value=np.nan)\n",
    "            temp1 = temp_1.filled(fill_value=np.nan)\n",
    "            temp_qc = temp_qc_1.filled(fill_value=np.nan)\n",
    "            sal1 = sal_1.filled(fill_value=np.nan)\n",
    "            sal_qc = sal_qc_1.filled(fill_value=np.nan)\n",
    "\n",
    "            pres1[pres_qc == b'3']= np.nan\n",
    "            pres1[pres_qc == b'4']= np.nan\n",
    "            temp1[temp_qc == b'3']= np.nan\n",
    "            temp1[temp_qc == b'4']= np.nan\n",
    "            sal1[sal_qc == b'3']= np.nan\n",
    "            sal1[sal_qc == b'4']= np.nan\n",
    "\n",
    "            pres2 = pres1[(~np.isnan(pres1)) & (~np.isnan(sal1)) & (~np.isnan(temp1))]\n",
    "            temp2 = temp1[(~np.isnan(pres1)) & (~np.isnan(sal1)) & (~np.isnan(temp1))]\n",
    "            sal2 = sal1[(~np.isnan(pres1)) & (~np.isnan(sal1)) & (~np.isnan(temp1))]\n",
    "\n",
    "            ########################################################################################\n",
    "            # Declare output depths\n",
    "            #Output daepth values 0, 5 10, 15, ... 250\n",
    "            depth_output = np.linspace(0,250,51)\n",
    "            #######################################################################################\n",
    "    \n",
    "            pres3=pres2[pres2<=250] # Light profile computed if T/S have at least 10 good points in 0 to 250 m water column\n",
    "    \n",
    "            pres3=pres2[pres2<=250] # Light profile computed if T/S have at least 15 good points in 0 to 250 m water column\n",
    "            pres4=pres2[pres2<=50] # Light profile computed if T/S have at least 5 good points in 0 to 50 m water column\n",
    "            if (len(pres3)>=15) & (len(pres4)>=5): # selected T/S profiles qualified above criterias\n",
    "                #######################################################################################\n",
    "                ##### EXTRACTING MLD ##################################################################\n",
    "                #######################################################################################               \n",
    "                # Derive Density Sigma0 and MLD from Temperature and Salinity profile\n",
    "                # No need to change anything in this section by the user\n",
    "                SA = gsw.SA_from_SP(sal2, pres2, LON, LAT) # Abslute salinity from practical salinity\n",
    "                CT = gsw.CT_from_t(SA, temp2, pres2) # Conservative Temperature from in-situ sea water temperature\n",
    "                dens = gsw.density.sigma0(SA,CT) # Potential density\n",
    "                MLD_1 = find_MLD(Z=pres2, dens=dens, threshold = 0.03)\n",
    "                # print('MLD is :', MLD_1,'m')\n",
    "        \n",
    "                #######################################################################################\n",
    "                ##### EXTRACTING DOY FROM NC ARGO FILE ################################################\n",
    "                #######################################################################################\n",
    "                JULD = NC.variables['JULD'][:]\n",
    "                # #Get day, month, year from juld\n",
    "                ref_date = '19500101000000'\n",
    "                JULD_n = int(JULD*86400)\n",
    "                date_prof = pd.to_datetime(ref_date,format='%Y%m%d%H%M%S') + timedelta(seconds=JULD_n)\n",
    "                year_prof = date_prof.strftime('%Y')\n",
    "                month_prof = date_prof.strftime('%m')\n",
    "                day_prof = date_prof.strftime('%d')\n",
    "                DOY = int(date_prof.strftime('%j'))\n",
    "                # print('DOY is:' ,DOY)\n",
    "                # No need to change anything in this section by the user\n",
    "                sin_doy = np.sin(rad_date(DOY))\n",
    "                cos_doy = np.cos(rad_date(DOY))\n",
    "\n",
    "                ########################################################################################################\n",
    "                # Extract local time from the nc file and convert into radiance and then transform into Sine and Cosine\n",
    "                ########################################################################################################\n",
    "                timezone_str = tf.certain_timezone_at(lat=LAT, lng=LON)\n",
    "                timezone = pytz.timezone(timezone_str)\n",
    "                # date_prof is in GMT time scale\n",
    "                LC = date_prof + timezone.utcoffset(date_prof) # +\n",
    "                GMT_Hour = date_prof.strftime('%H')\n",
    "                LC_Hour = LC.strftime('%H') \n",
    "    \n",
    "                GMT_Hour_Min = date_prof.strftime('%H:%M')\n",
    "                LC_Hour_Min = LC.strftime('%H:%M')  \n",
    "                LC_Hour_Deci = (int(LC_Hour_Min[0:2]) + int(LC_Hour_Min[3:])/60)\n",
    "\n",
    "                # LC_hour = 12\n",
    "                sin_LC_hour = np.sin(rad_LC_hour(LC_Hour_Deci))\n",
    "                cos_LC_hour = np.cos(rad_LC_hour(LC_Hour_Deci))\n",
    "                ####################################################################################### \n",
    "                #######################################################################################\n",
    "                # No need to change anything in this section by the user\n",
    "                # HOW to use this function\n",
    "        \n",
    "                if(not np.isnan(MLD_1) and not np.isnan(PAR) and not np.isnan(KD490)and\n",
    "                   not np.isnan(RHO412) and not np.isnan(RHO443) and not np.isnan(RHO490) and\n",
    "                   not np.isnan(RHO555) and not np.isnan(RHO670)):\n",
    "                    PAR_ADJUSTED=PAR_ADJUSTED_profiles(PAR=PAR, MLD=MLD_1, ZPD=derive_ZPD(float(KD490)), RHO_WN_412=RHO412, RHO_WN_443=RHO443,\n",
    "                                                       RHO_WN_490=RHO490, RHO_WN_555=RHO555, RHO_WN_670=RHO670, sin_doy=sin_doy,\n",
    "                                                       cos_doy=cos_doy, sin_LC_hour=sin_LC_hour, cos_LC_hour=cos_LC_hour,\n",
    "                                                       temp=temp2, sal=sal2, depths_argo=pres2, depth_output=depth_output)[0]\n",
    "                    ED380_ADJUSTED=ED380_ADJUSTED_profiles(PAR=PAR, MLD=MLD_1, ZPD=derive_ZPD(float(KD490)), RHO_WN_412=RHO412, RHO_WN_443=RHO443,\n",
    "                                                       RHO_WN_490=RHO490, RHO_WN_555=RHO555, RHO_WN_670=RHO670, sin_doy=sin_doy,\n",
    "                                                       cos_doy=cos_doy, sin_LC_hour=sin_LC_hour, cos_LC_hour=cos_LC_hour,\n",
    "                                                       temp=temp2, sal=sal2, depths_argo=pres2, depth_output=depth_output)[0]\n",
    "                    ED412_ADJUSTED=ED412_ADJUSTED_profiles(PAR=PAR, MLD=MLD_1, ZPD=derive_ZPD(float(KD490)), RHO_WN_412=RHO412, RHO_WN_443=RHO443,\n",
    "                                                       RHO_WN_490=RHO490, RHO_WN_555=RHO555, RHO_WN_670=RHO670, sin_doy=sin_doy,\n",
    "                                                       cos_doy=cos_doy, sin_LC_hour=sin_LC_hour, cos_LC_hour=cos_LC_hour,\n",
    "                                                       temp=temp2, sal=sal2, depths_argo=pres2, depth_output=depth_output)[0]\n",
    "                    ED490_ADJUSTED=ED490_ADJUSTED_profiles(PAR=PAR, MLD=MLD_1, ZPD=derive_ZPD(float(KD490)), RHO_WN_412=RHO412, RHO_WN_443=RHO443,\n",
    "                                                       RHO_WN_490=RHO490, RHO_WN_555=RHO555, RHO_WN_670=RHO670, sin_doy=sin_doy,\n",
    "                                                       cos_doy=cos_doy, sin_LC_hour=sin_LC_hour, cos_LC_hour=cos_LC_hour,\n",
    "                                                       temp=temp2, sal=sal2, depths_argo=pres2, depth_output=depth_output)[0]                   \n",
    "        \n",
    "                else:\n",
    "                    PAR_ADJUSTED = np.nan\n",
    "                    ED380_ADJUSTED = np.nan\n",
    "                    ED412_ADJUSTED = np.nan\n",
    "                    ED490_ADJUSTED = np.nan\n",
    "            else: # If temp/Sal criteria fails\n",
    "                PAR_ADJUSTED = np.nan\n",
    "                ED380_ADJUSTED = np.nan\n",
    "                ED412_ADJUSTED = np.nan\n",
    "                ED490_ADJUSTED = np.nan\n",
    "        else: # Temp and Sal not in delayed mode\n",
    "            PAR_ADJUSTED = np.nan\n",
    "            ED380_ADJUSTED = np.nan\n",
    "            ED412_ADJUSTED = np.nan\n",
    "            ED490_ADJUSTED = np.nan\n",
    "    else: # If there is no BGC Argo file\n",
    "        PAR_ADJUSTED = np.nan\n",
    "        ED380_ADJUSTED = np.nan\n",
    "        ED412_ADJUSTED = np.nan\n",
    "        ED490_ADJUSTED = np.nan\n",
    "              \n",
    "    # #########################################################################################\n",
    "    # ##########       \n",
    "    db_par = {'depth': depth_output, 'PAR_ADJUSTED': PAR_ADJUSTED} \n",
    "    db_par = pd.DataFrame(db_par)\n",
    "    db_par= db_par.round({'depth': 0, 'PAR_ADJUSTED': 4}) # Output adjusted to 4 decimal places\n",
    "    \n",
    "    db_ed380 = {'depth': depth_output, 'ED380_ADJUSTED': ED380_ADJUSTED} \n",
    "    db_ed380 = pd.DataFrame(db_ed380)\n",
    "    db_ed380 = db_ed380.round({'depth': 0, 'ED380_ADJUSTED': 5}) # Output adjusted to 5 decimal places\n",
    "    \n",
    "    db_ed412 = {'depth': depth_output, 'ED412_ADJUSTED': ED412_ADJUSTED} \n",
    "    db_ed412 = pd.DataFrame(db_ed412)\n",
    "    db_ed412 = db_ed412.round({'depth': 0, 'ED412_ADJUSTED': 5}) # Output adjusted to 5 decimal places\n",
    "    \n",
    "    db_ed490 = {'depth': depth_output, 'ED490_ADJUSTED': ED490_ADJUSTED} \n",
    "    db_ed490 = pd.DataFrame(db_ed490)\n",
    "    db_ed490 = db_ed490.round({'depth': 0, 'ED490_ADJUSTED': 5}) # Output adjusted to 5 decimal places    \n",
    "    \n",
    "    ###########################################################################################\n",
    "    db_par.to_csv(PAR_output_file, sep=',', index= False)\n",
    "    db_ed380.to_csv(ED380_output_file, sep=',', index= False)   \n",
    "    db_ed412.to_csv(ED412_output_file, sep=',', index= False)   \n",
    "    db_ed490.to_csv(ED490_output_file, sep=',', index= False)   \n",
    "       \n",
    "    print(i)\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61745a5-de38-4c32-91a4-b241df284d61",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd04b4-4519-4928-a1b0-dd898ec5b626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJ_1",
   "language": "python",
   "name": "proj_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
